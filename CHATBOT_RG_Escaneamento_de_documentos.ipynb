{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ManciniGa/Aprendizado-Profundo/blob/main/CHATBOT_RG_Escaneamento_de_documentos.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EuESSk_9dKMa"
      },
      "source": [
        "# OCR Projeto 02: Escaneamento de imagem\n",
        "\n",
        "\n",
        "---\n",
        "Este projeto combina técnicas de processamento de linguagem natural (NLP) e interface gráfica para criar um chatbot interativo capaz de validar e responder a perguntas sobre informações extraídas de documentos, como CPF, RG e data de emissão. Utilizando o modelo pré-treinado **DistilBERT**, especializado em perguntas e respostas, e a biblioteca **Gradio** para interface, o sistema processa entradas do usuário em texto e realiza validações estruturais, como verificar se um CPF possui 11 dígitos ou se a data de emissão do RG é inferior a 10 anos. Além disso, o projeto emprega ferramentas de pré-processamento, incluindo extração de números com expressões regulares, para garantir a correta interpretação do contexto textual. Essa integração fornece um ambiente robusto para interações precisas e amigáveis, combinando inteligência artificial e acessibilidade.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5xQpLj93WXDJ"
      },
      "source": [
        "# Importando as bibliotecas"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZYOaX_yRgFqO"
      },
      "source": [
        "# Importando a biblioteca NumPy, usada para operações numéricas eficientes, especialmente com arrays e matrizes.\n",
        "import numpy as np\n",
        "\n",
        "# Importando a biblioteca OpenCV (cv2), amplamente utilizada para processamento de imagens e visão computacional.\n",
        "import cv2\n",
        "\n",
        "# Importando a biblioteca imutils, que contém funções auxiliares para manipulação de imagens e simplificação do código com OpenCV.\n",
        "import imutils\n",
        "\n",
        "# Importando uma ferramenta específica do Google Colab que permite exibir imagens diretamente no ambiente de notebook.\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "# Importando pyplot da biblioteca Matplotlib, que é usada para visualização de dados, incluindo gráficos e imagens.\n",
        "from matplotlib import pyplot as plt\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "10Fp9ew0Wcpt"
      },
      "source": [
        "# Conectando com o Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fsanJQff1NDm",
        "outputId": "9f7c17f1-74be-472d-bea6-502df7b03c3d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2RrqJYeHWhoi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "37b08d41-9440-4418-feb9-8c58f96fe969"
      },
      "source": [
        "# Comando para copiar arquivos e diretórios recursivamente.\n",
        "!cp -R /content/gdrive/MyDrive/Cursos\\ -\\ recursos/OCR\\ com\\ Python/Imagens/Projeto2 imagens/\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cp: cannot stat '/content/gdrive/MyDrive/Cursos - recursos/OCR com Python/Imagens/Projeto2': No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oEWrEvWegHPx"
      },
      "source": [
        "def mostrar(img):\n",
        "    # Obtém a figura atual ou cria uma nova figura no Matplotlib.\n",
        "    fig = plt.gcf()\n",
        "\n",
        "    # Define o tamanho da figura em polegadas: largura de 20 e altura de 10.\n",
        "    fig.set_size_inches(20, 10)\n",
        "\n",
        "    # Remove os eixos da imagem para exibir apenas a imagem.\n",
        "    plt.axis(\"off\")\n",
        "\n",
        "    # Converte a imagem de BGR (formato padrão do OpenCV) para RGB (formato padrão do Matplotlib),\n",
        "    # para garantir que as cores sejam exibidas corretamente.\n",
        "    plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
        "\n",
        "    # Exibe a imagem na tela.\n",
        "    plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z-qiSoJwvTEn"
      },
      "source": [
        "# Processamentos na imagem (para transformação)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def mostrar(img):\n",
        "    # Obtém a figura atual ou cria uma nova figura para exibição.\n",
        "    fig = plt.gcf()\n",
        "\n",
        "    # Define o tamanho da figura (em polegadas) como 20 de largura e 10 de altura.\n",
        "    fig.set_size_inches(20, 10)\n",
        "\n",
        "    # Desativa a exibição dos eixos para focar apenas na imagem.\n",
        "    plt.axis(\"off\")\n",
        "\n",
        "    # Exibe a imagem, convertendo-a de BGR (formato padrão do OpenCV) para RGB\n",
        "    # (formato esperado pelo Matplotlib) para que as cores apareçam corretamente.\n",
        "    plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
        "\n",
        "    # Mostra a imagem processada no ambiente do Matplotlib.\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "IEcnlYudyOv9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "bfO0KsTv04GU",
        "outputId": "497b2bd4-c3f2-4529-8d70-9db082dc9971"
      },
      "source": [
        "# Lê a imagem a partir do caminho especificado no formato padrão do OpenCV (BGR).\n",
        "#img = cv2.imread('/content/drive/MyDrive/Mestrado/Unesp/Disciplinas/Aprendizado Profundo/Aprendizado Profundo Tema - (Visual Reasoning)/RG.jpg')\n",
        "img = cv2.imread('/content/RG.jpg')\n",
        "\n",
        "# Cria uma cópia da imagem original para preservar a versão inicial.\n",
        "original = img.copy()\n",
        "\n",
        "# Chama a função mostrar para exibir a imagem carregada.\n",
        "mostrar(img)\n",
        "\n",
        "# Obtém as dimensões da imagem (altura H e largura W) a partir do atributo shape.\n",
        "# shape[:2] retorna as duas primeiras dimensões: altura (H) e largura (W).\n",
        "(H, W) = img.shape[:2]\n",
        "\n",
        "# Imprime as dimensões da imagem (altura e largura).\n",
        "print(H, W)\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'cv2' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-6b6beae34cd8>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Lê a imagem a partir do caminho especificado no formato padrão do OpenCV (BGR).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m#img = cv2.imread('/content/drive/MyDrive/Mestrado/Unesp/Disciplinas/Aprendizado Profundo/Aprendizado Profundo Tema - (Visual Reasoning)/RG.jpg')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/RG.jpg'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Cria uma cópia da imagem original para preservar a versão inicial.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'cv2' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K0UIrwwevVxR"
      },
      "source": [
        "## Conversão para tons de cinza (*grayscale*)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "NhbczeNL1VN4",
        "outputId": "483a40d9-860c-42ca-d481-84c60b24b0f6"
      },
      "source": [
        "# Converte a imagem original de BGR (padrão do OpenCV) para tons de cinza.\n",
        "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "# Exibe a imagem em tons de cinza usando a função 'mostrar'.\n",
        "mostrar(gray)\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'cv2' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-27f0a77c62df>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Converte a imagem original de BGR (padrão do OpenCV) para tons de cinza.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mgray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCOLOR_BGR2GRAY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Exibe a imagem em tons de cinza usando a função 'mostrar'.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mmostrar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'cv2' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wHWDHa721XAe"
      },
      "source": [
        "## Aplicação de desfoque (*Gaussian Blur*)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sfWwRY6z1a0F"
      },
      "source": [
        "# Aplica um desfoque gaussiano à imagem em tons de cinza.\n",
        "# O kernel de tamanho (5, 5) é usado para suavizar a imagem.\n",
        "# O parâmetro sigmaX (último argumento) é definido como 0, para que o OpenCV calcule automaticamente.\n",
        "blur = cv2.GaussianBlur(gray, (5, 5), 0)\n",
        "\n",
        "# Exibe a imagem suavizada (desfocada) usando a função 'mostrar'.\n",
        "mostrar(blur)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NoZlUVeJvZcj"
      },
      "source": [
        "## Detecção de bordas (*Canny Edge*)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "347df2WN1fqO"
      },
      "source": [
        "# Aplica o detector de bordas Canny na imagem suavizada (blur).\n",
        "# Os parâmetros 60 e 160 definem os limiares inferior e superior para a detecção de bordas.\n",
        "edged = cv2.Canny(blur, 60, 160)\n",
        "\n",
        "# Exibe a imagem resultante com as bordas detectadas.\n",
        "mostrar(edged)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I8YjWqtvvhhX"
      },
      "source": [
        "# Detecção de contornos na imagem"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6iNNi6oo3PE6"
      },
      "source": [
        "def encontrar_contornos(img):\n",
        "    # Encontra os contornos na imagem.\n",
        "    # cv2.RETR_LIST: Recupera todos os contornos encontrados sem organizar hierarquicamente.\n",
        "    # cv2.CHAIN_APPROX_SIMPLE: Armazena apenas os pontos essenciais dos contornos, economizando memória.\n",
        "    conts = cv2.findContours(img, cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)\n",
        "\n",
        "    # Ajusta a saída de findContours para ser compatível com diferentes versões do OpenCV.\n",
        "    conts = imutils.grab_contours(conts)\n",
        "\n",
        "    # Ordena os contornos por área em ordem decrescente (maiores primeiro).\n",
        "    # Pega apenas os 6 maiores contornos.\n",
        "    conts = sorted(conts, key=cv2.contourArea, reverse=True)[:6]\n",
        "\n",
        "    # Retorna os contornos processados.\n",
        "    return conts\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0qVXaCI87ih-"
      },
      "source": [
        "# Chama a função 'encontrar_contornos', passando uma cópia da imagem de bordas (edged).\n",
        "# Isso garante que a imagem original de bordas não seja alterada durante o processamento.\n",
        "# A função retorna os contornos mais significativos encontrados na imagem (até 6 maiores).\n",
        "conts = encontrar_contornos(edged.copy())\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ilFZs4Y-vliJ"
      },
      "source": [
        "## Localizando o maior contorno\n",
        "\n",
        "- Douglas-Peucker: http://en.wikipedia.org/wiki/Ramer-Douglas-Peucker_algorithm"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LLBpi0hfURRD"
      },
      "source": [
        "# Percorre cada contorno encontrado na lista 'conts'.\n",
        "for c in conts:\n",
        "    # Calcula o perímetro do contorno.\n",
        "    # O segundo argumento (True) indica que o contorno é fechado.\n",
        "    perimetro = cv2.arcLength(c, True)\n",
        "\n",
        "    # Aproxima o contorno a uma forma poligonal com menos vértices.\n",
        "    # A precisão da aproximação é definida como 2% do perímetro do contorno.\n",
        "    aproximacao = cv2.approxPolyDP(c, 0.02 * perimetro, True)\n",
        "\n",
        "    # Verifica se o contorno aproximado tem exatamente 4 vértices.\n",
        "    # Isso indica que o contorno é possivelmente um quadrilátero.\n",
        "    if len(aproximacao) == 4:\n",
        "        # Se encontrar um contorno com 4 vértices, o armazena na variável 'maior'.\n",
        "        maior = aproximacao\n",
        "\n",
        "        # Sai do loop, pois já encontrou o contorno desejado.\n",
        "        break"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SV1SzdhyVp_m"
      },
      "source": [
        "# Desenha o contorno 'maior' na imagem original 'img'.\n",
        "# O argumento -1 indica que todos os contornos serão desenhados (no caso, é apenas um).\n",
        "# A cor do contorno é definida como (120, 255, 0) (verde em formato BGR).\n",
        "# A espessura do contorno é definida como 28 pixels.\n",
        "cv2.drawContours(img, maior, -1, (120, 255, 0), 28)\n",
        "\n",
        "# Desenha novamente o contorno 'maior' na imagem, mas desta vez como uma lista de contornos.\n",
        "# A cor do contorno é a mesma, mas a espessura é reduzida para 2 pixels.\n",
        "cv2.drawContours(img, [maior], -1, (120, 255, 0), 2)\n",
        "\n",
        "# Exibe a imagem modificada com os contornos desenhados usando a função 'mostrar'.\n",
        "mostrar(img)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UB3o2FOKQ__U"
      },
      "source": [
        "## Ordenando os pontos\n",
        "\n",
        "Nós ja temos as 4 coordenadas x-y que correspondem aos cantos do retângulo/polígono localizado na imagem, porém esses pontos provavelmente estarão fora de uma ordem. Para fazer a transformação de perspectiva precisamos ordenar os pontos, de modo que eles fiquem em uma ordem padrão e assim seja possível aplicar a transformação.\n",
        "\n",
        "É crucial que a ordem dos pontos do retângulo esteja consistente em todo o programa. Pois caso mude de ordem algum desses pontos a transformação não vai ficar da forma que queremos.\n",
        "\n",
        "Nós escolhemos essa ordem:\n",
        "\n",
        "1. **te** = topo esquerdo (superior esquerdo)\n",
        "2. **td** = topo direito (superior direito)\n",
        "3. **bd** = baixo direito (inferior direito)\n",
        "4. **be** = baixo esquerdo (inferior esquerdo)\n",
        "\n",
        "Preferimos deixar nessa ordem por ser um padrão mais utilizado. Você poderia se quiser mudar a ordem, deixar por exemplo `be` antes de `bd` e após `td`, só que se for fazer assim precisa manter essa ordem no restante do programa (especificamente na parte do pts2 que veremos abaixo, trocando o [W, H] por [0, H])"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RsLmJd_lWq7H"
      },
      "source": [
        "def ordenar_pontos(pontos):\n",
        "    # Reorganiza os pontos fornecidos para formar uma matriz 4x2 (quatro pontos, cada um com coordenadas x e y).\n",
        "    pontos = pontos.reshape((4, 2))\n",
        "\n",
        "    # Cria uma nova matriz para armazenar os pontos ordenados.\n",
        "    # A forma final será 4x1x2 (compatível com OpenCV), com valores inteiros de 32 bits.\n",
        "    pontos_novos = np.zeros((4, 1, 2), dtype=np.int32)\n",
        "\n",
        "    # Soma as coordenadas x e y de cada ponto.\n",
        "    add = pontos.sum(1)\n",
        "\n",
        "    # O ponto com a menor soma (x + y) será o canto superior esquerdo.\n",
        "    pontos_novos[0] = pontos[np.argmin(add)]\n",
        "\n",
        "    # O ponto com a maior soma (x + y) será o canto inferior direito.\n",
        "    pontos_novos[2] = pontos[np.argmax(add)]\n",
        "\n",
        "    # Calcula a diferença entre as coordenadas x e y de cada ponto.\n",
        "    dif = np.diff(pontos, axis=1)\n",
        "\n",
        "    # O ponto com a menor diferença (x - y) será o canto superior direito.\n",
        "    pontos_novos[1] = pontos[np.argmin(dif)]\n",
        "\n",
        "    # O ponto com a maior diferença (x - y) será o canto inferior esquerdo.\n",
        "    pontos_novos[3] = pontos[np.argmax(dif)]\n",
        "\n",
        "    # Retorna os pontos ordenados como uma matriz 4x1x2.\n",
        "    return pontos_novos\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GbvryF2IX8Ka",
        "outputId": "d47a4017-e5f3-47a6-caea-a3698b336496"
      },
      "source": [
        "# Ordena os pontos do quadrilátero armazenado em 'maior' usando a função 'ordenar_pontos'.\n",
        "# Isso garante que os pontos sejam organizados em uma ordem consistente:\n",
        "# - Canto superior esquerdo\n",
        "# - Canto superior direito\n",
        "# - Canto inferior direito\n",
        "# - Canto inferior esquerdo\n",
        "pontos_maior = ordenar_pontos(maior)\n",
        "\n",
        "# Imprime os pontos ordenados do quadrilátero na saída.\n",
        "print(pontos_maior)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[[ 52  55]]\n",
            "\n",
            " [[595  54]]\n",
            "\n",
            " [[597 425]]\n",
            "\n",
            " [[ 47 419]]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0MyExwOisnJD"
      },
      "source": [
        "## Obtenção da matriz de transformação"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DtuLNMPucFzT"
      },
      "source": [
        "# Converte os pontos ordenados do quadrilátero ('pontos_maior') para o formato de ponto flutuante (float32).\n",
        "# Isso é necessário para algumas operações do OpenCV, como transformações de perspectiva,\n",
        "# que requerem coordenadas no formato float.\n",
        "pts1 = np.float32(pontos_maior)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TZziUxhRcmFp",
        "outputId": "755c33bd-f881-483d-e46a-2191e771e0f6"
      },
      "source": [
        "# Exibe os valores de altura (H) e largura (W) da imagem, que foram previamente calculados.\n",
        "# H representa a altura (número de linhas na imagem).\n",
        "# W representa a largura (número de colunas na imagem).\n",
        "print(H, W)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "480 652\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L6X0qVfycdcc"
      },
      "source": [
        "# Define os pontos de destino (pts2) para uma transformação de perspectiva.\n",
        "# Esses pontos representam as coordenadas de um retângulo em uma imagem com dimensões W (largura) e H (altura).\n",
        "# O formato float32 é necessário para operações do OpenCV.\n",
        "pts2 = np.float32([[0, 0], [W, 0], [W, H], [0, H]])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TE67us0sdi2U",
        "outputId": "5700cc06-77e9-4e55-deac-a70028196f8a"
      },
      "source": [
        "# Calcula a matriz de transformação de perspectiva que mapeia os pontos de origem (pts1) para os pontos de destino (pts2).\n",
        "# Essa matriz 3x3 é usada para realizar a transformação de perspectiva.\n",
        "matriz = cv2.getPerspectiveTransform(pts1, pts2)\n",
        "\n",
        "# Exibe a matriz de transformação de perspectiva calculada.\n",
        "matriz\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 1.22825666e+00,  1.68716574e-02, -6.47972875e+01],\n",
              "       [ 2.46906477e-03,  1.34070217e+00, -7.38670106e+01],\n",
              "       [ 3.52233818e-05,  3.58423054e-05,  1.00000000e+00]])"
            ]
          },
          "metadata": {},
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eZyXRdFJsh1U"
      },
      "source": [
        "## Transformação de perspectiva"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VMtGcY48dvRv"
      },
      "source": [
        "# Aplica a transformação de perspectiva à imagem original.\n",
        "# 'original': imagem que será transformada.\n",
        "# 'matriz': matriz de transformação de perspectiva calculada anteriormente.\n",
        "# '(W, H)': define o tamanho da imagem resultante (largura W e altura H).\n",
        "transform = cv2.warpPerspective(original, matriz, (W, H))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bUpbrfk_d1j4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        },
        "outputId": "e31da10f-0efb-4cf4-9794-e97f1200f941"
      },
      "source": [
        "# Exibe a imagem transformada (retificada) usando a função personalizada 'mostrar'.\n",
        "# A função converte a imagem de BGR para RGB e remove os eixos antes de exibi-la.\n",
        "mostrar(transform)\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'mostrar' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-e05cea55dc0f>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Exibe a imagem transformada (retificada) usando a função personalizada 'mostrar'.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# A função converte a imagem de BGR para RGB e remove os eixos antes de exibi-la.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmostrar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'mostrar' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CwRam9sTQBiB"
      },
      "source": [
        "# OCR com Tesseract"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zeV-sDDVQBCk",
        "outputId": "a4c41570-0bca-4f73-ec5a-801ce25914d0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Instala o Tesseract OCR no ambiente.\n",
        "# Tesseract é um mecanismo de OCR (Reconhecimento Óptico de Caracteres) que converte imagens em texto.\n",
        "!sudo apt install tesseract-ocr\n",
        "# Instala a biblioteca Python 'pytesseract'.\n",
        "# Esta biblioteca funciona como uma interface para o Tesseract OCR, permitindo usá-lo diretamente em Python.\n",
        "!pip install pytesseract\n",
        "# Importa a biblioteca 'pytesseract', que será usada para realizar OCR em imagens.\n",
        "import pytesseract\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "tesseract-ocr is already the newest version (4.1.1-2.1build1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 49 not upgraded.\n",
            "Requirement already satisfied: pytesseract in /usr/local/lib/python3.10/dist-packages (0.3.13)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.10/dist-packages (from pytesseract) (24.2)\n",
            "Requirement already satisfied: Pillow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from pytesseract) (11.0.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ffU8DI6cQHgb",
        "outputId": "74e9ab5d-b461-41ab-b8d7-ada14e915a66",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Cria um diretório chamado 'tessdata' no local atual para armazenar os arquivos de treinamento do Tesseract.\n",
        "!mkdir tessdata\n",
        "# Faz o download do arquivo de treinamento do idioma português (por.traineddata) e o salva na pasta 'tessdata'.\n",
        "# O arquivo é baixado diretamente do repositório oficial do Tesseract no GitHub.\n",
        "!wget -O ./tessdata/por.traineddata https://github.com/tesseract-ocr/tessdata/blob/master/por.traineddata?raw=true\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mkdir: cannot create directory ‘tessdata’: File exists\n",
            "--2024-11-23 17:50:09--  https://github.com/tesseract-ocr/tessdata/blob/master/por.traineddata?raw=true\n",
            "Resolving github.com (github.com)... 140.82.116.3\n",
            "Connecting to github.com (github.com)|140.82.116.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://github.com/tesseract-ocr/tessdata/blob/main/por.traineddata [following]\n",
            "--2024-11-23 17:50:09--  https://github.com/tesseract-ocr/tessdata/blob/main/por.traineddata\n",
            "Reusing existing connection to github.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./tessdata/por.traineddata’\n",
            "\n",
            "./tessdata/por.trai     [ <=>                ] 294.83K  --.-KB/s    in 0.03s   \n",
            "\n",
            "2024-11-23 17:50:10 (9.24 MB/s) - ‘./tessdata/por.traineddata’ saved [301907]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Instala o pacote de idioma português para o Tesseract OCR no sistema.\n",
        "!sudo apt-get install tesseract-ocr-por"
      ],
      "metadata": {
        "id": "psFRLnigwplX",
        "outputId": "d2e6821b-67a0-4765-d72e-96ae365d6855",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "tesseract-ocr-por is already the newest version (1:4.00~git30-7274cfa-1.1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 49 not upgraded.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "4p5D89RUQOgq",
        "outputId": "5b95e6c6-e8c2-4a4e-ac8e-a0954b25a959"
      },
      "source": [
        "# Define o caminho para o diretório de dados do Tesseract onde os arquivos de treinamento de idiomas estão localizados.\n",
        "# A primeira linha está comentada porque é usada se o arquivo 'por.traineddata' estiver em um diretório personalizado (ex.: 'tessdata' local).\n",
        "# config_tesseract = \"--tessdata-dir tessdata\"\n",
        "\n",
        "# Usa o diretório padrão onde o Tesseract armazena os arquivos de treinamento do sistema.\n",
        "config_tesseract = \"--tessdata-dir /usr/share/tesseract-ocr/4.00/tessdata\"\n",
        "\n",
        "# Executa o OCR na imagem 'transform', especificando o idioma como português (lang=\"por\").\n",
        "# Inclui a configuração 'config_tesseract' para apontar o diretório de dados do Tesseract.\n",
        "texto = pytesseract.image_to_string(transform, lang=\"por\", config=config_tesseract)\n",
        "\n",
        "# Exibe o texto extraído da imagem.\n",
        "print(texto)\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'pytesseract' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-00cbcbe9e658>\u001b[0m in \u001b[0;36m<cell line: 10>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# Executa o OCR na imagem 'transform', especificando o idioma como português (lang=\"por\").\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# Inclui a configuração 'config_tesseract' para apontar o diretório de dados do Tesseract.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mtexto\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpytesseract\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage_to_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlang\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"por\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig_tesseract\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m# Exibe o texto extraído da imagem.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'pytesseract' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "veYpWzO_ys7X",
        "outputId": "bee287e3-8e98-4494-c997-12fb4a956138"
      },
      "source": [
        "# Redimensiona a imagem 'transform' para aumentar o tamanho, facilitando a leitura pelo OCR.\n",
        "# 'fx=1.5' e 'fy=1.5' aumentam a largura e altura em 1.5 vezes, respectivamente.\n",
        "# 'interpolation=cv2.INTER_CUBIC' usa interpolação cúbica, adequada para redimensionar imagens com boa qualidade.\n",
        "maior = cv2.resize(transform, None, fx=1.5, fy=1.5, interpolation=cv2.INTER_CUBIC)\n",
        "\n",
        "# Executa o OCR na imagem redimensionada 'maior', usando o idioma português.\n",
        "texto = pytesseract.image_to_string(maior, lang=\"por\", config=config_tesseract)\n",
        "\n",
        "# Executa novamente o OCR na imagem redimensionada, caso a leitura precise ser armazenada separadamente.\n",
        "# Isso pode ser redundante se os textos esperados forem iguais.\n",
        "texto2 = pytesseract.image_to_string(maior, lang=\"por\", config=config_tesseract)\n",
        "\n",
        "# Exibe o texto extraído da imagem na saída.\n",
        "print(texto)\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'cv2' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-ba1488f40264>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# 'fx=1.5' e 'fy=1.5' aumentam a largura e altura em 1.5 vezes, respectivamente.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# 'interpolation=cv2.INTER_CUBIC' usa interpolação cúbica, adequada para redimensionar imagens com boa qualidade.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mmaior\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minterpolation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mINTER_CUBIC\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# Executa o OCR na imagem redimensionada 'maior', usando o idioma português.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'cv2' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"Este é um exemplo de texto extraído da imagem. O Tesseract OCR interpreta os caracteres e os transforma em texto.\"\n",
        "texto"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "WHERJYRQy908",
        "outputId": "0ad670cf-3501-489d-b8ac-fa9674740e3b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' \\n     \\n   \\n \\n   \\n\\n \\n\\nor 426993068/35 ONI\\nREGISTRO GERAL 40.089.659-X 2via DATA DE EXPEDIÇÃO 27/08/2024\\n\\n& REGISTRO Civil\\n* RIO CLARO-SP CORUMBATAÍ CN:LV.AL6 /FLS.138 /Nº07726\\n\\n \\n\\nSÉRIE UF\\n\\x0c'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "# O texto extraído da imagem pelo Tesseract é armazenado na variável 'texto'.\n",
        "# Aqui, estamos reutilizando a variável 'texto' já existente.\n",
        "texto = texto\n",
        "\n",
        "# Usando uma expressão regular para encontrar todos os dígitos individuais no texto.\n",
        "# O padrão '\\d' corresponde a qualquer caractere numérico (0-9).\n",
        "digitos = re.findall(r'\\d', texto)\n",
        "\n",
        "# Converte os dígitos encontrados (que estão como strings) para inteiros usando map().\n",
        "# Cada elemento da lista é convertido de string para inteiro.\n",
        "digitos_inteiros = list(map(int, digitos))\n",
        "\n",
        "# Exibindo os dígitos extraídos como strings.\n",
        "print(\"Dígitos extraídos:\", digitos)\n",
        "\n",
        "# Exibindo os dígitos convertidos para inteiros.\n",
        "print(\"Dígitos como inteiros:\", digitos_inteiros)\n",
        "\n",
        "# Armazena os dígitos extraídos como strings em 'texto2'.\n",
        "texto2 = digitos"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "_qmQ15D9z5DT",
        "outputId": "00e1f966-9ae2-465f-e62b-20415c8398e8"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'texto' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-62c2ae18b179>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# O texto extraído da imagem pelo Tesseract é armazenado na variável 'texto'.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Aqui, estamos reutilizando a variável 'texto' já existente.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mtexto\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtexto\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# Usando uma expressão regular para encontrar todos os dígitos individuais no texto.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'texto' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "# Definindo o texto extraído pelo Tesseract (presume-se que a variável 'texto' já exista com o conteúdo processado).\n",
        "texto = texto\n",
        "\n",
        "# Usando expressões regulares para encontrar todos os dígitos no texto.\n",
        "# '\\d' encontra todos os caracteres numéricos, e 'findall' retorna uma lista com eles.\n",
        "digitos = re.findall(r'\\d', texto)\n",
        "\n",
        "# Converte os dígitos (que estão como strings) em inteiros usando map().\n",
        "digitos_inteiros = list(map(int, digitos))\n",
        "\n",
        "# Dividindo os dígitos extraídos em diferentes categorias:\n",
        "\n",
        "# CPF: Seleciona os 11 primeiros dígitos.\n",
        "CPF = digitos_inteiros[:11]\n",
        "\n",
        "# RG: Seleciona do 12º ao 19º dígito.\n",
        "RG = digitos_inteiros[11:19]\n",
        "\n",
        "# DT: Seleciona os dígitos do 20º ao 28º (ajustado para considerar todos os 9 dígitos esperados).\n",
        "DT = digitos_inteiros[20:28]\n",
        "\n",
        "# Exibindo os resultados das categorias de dígitos.\n",
        "print(\"CPF:\", CPF)  # Os 11 dígitos que representam o CPF.\n",
        "print(\"RG:\", RG)    # Os próximos 8 dígitos que representam o RG.\n",
        "print(\"DT:\", DT)    # Os 8 dígitos que representam a data (DT).\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "_Hh2ub2V18b6",
        "outputId": "1c0f0441-e611-482c-c7e7-860642bd9f2f"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'texto' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-b55486ee6865>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Definindo o texto extraído pelo Tesseract (presume-se que a variável 'texto' já exista com o conteúdo processado).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mtexto\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtexto\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# Usando expressões regulares para encontrar todos os dígitos no texto.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'texto' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##CHATBOT"
      ],
      "metadata": {
        "id": "dj9pklW6x1AO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gradio\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ddhuZrgx2zlE",
        "outputId": "b9e90858-8597-4a2b-819a-8695a65aab5c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gradio in /usr/local/lib/python3.10/dist-packages (5.6.0)\n",
            "Requirement already satisfied: aiofiles<24.0,>=22.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (23.2.1)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.7.1)\n",
            "Requirement already satisfied: fastapi<1.0,>=0.115.2 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.115.5)\n",
            "Requirement already satisfied: ffmpy in /usr/local/lib/python3.10/dist-packages (from gradio) (0.4.0)\n",
            "Requirement already satisfied: gradio-client==1.4.3 in /usr/local/lib/python3.10/dist-packages (from gradio) (1.4.3)\n",
            "Requirement already satisfied: httpx>=0.24.1 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.27.2)\n",
            "Requirement already satisfied: huggingface-hub>=0.25.1 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.26.2)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.1.4)\n",
            "Requirement already satisfied: markupsafe~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.1.5)\n",
            "Requirement already satisfied: numpy<3.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (1.26.4)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.10.11)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from gradio) (24.2)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.2.2)\n",
            "Requirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (11.0.0)\n",
            "Requirement already satisfied: pydantic>=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.9.2)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.10/dist-packages (from gradio) (0.25.1)\n",
            "Requirement already satisfied: python-multipart==0.0.12 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.0.12)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (6.0.2)\n",
            "Requirement already satisfied: ruff>=0.2.2 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.8.0)\n",
            "Requirement already satisfied: safehttpx<1.0,>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.1.1)\n",
            "Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.10.0)\n",
            "Requirement already satisfied: starlette<1.0,>=0.40.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.41.3)\n",
            "Requirement already satisfied: tomlkit==0.12.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.12.0)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.13.0)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (4.12.2)\n",
            "Requirement already satisfied: uvicorn>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.32.1)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from gradio-client==1.4.3->gradio) (2024.10.0)\n",
            "Requirement already satisfied: websockets<13.0,>=10.0 in /usr/local/lib/python3.10/dist-packages (from gradio-client==1.4.3->gradio) (12.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio) (1.2.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio) (2024.8.30)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.14.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.25.1->gradio) (3.16.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.25.1->gradio) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.25.1->gradio) (4.66.6)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio) (2024.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->gradio) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->gradio) (2.23.4)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (8.1.7)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (13.9.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio) (1.16.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.18.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.25.1->gradio) (3.4.0)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.25.1->gradio) (2.2.3)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import gradio as gr\n",
        "from datetime import datetime  # Para trabalhar com datas.\n",
        "from transformers import pipeline\n",
        "\n",
        "# Vetores de dígitos simulando extração de texto de documentos.\n",
        "CPF = CPF    # Lista de 11 dígitos representando um CPF.\n",
        "RG = RG      # Lista de 8 dígitos representando um RG.\n",
        "DT = DT      # Lista de 8 dígitos representando a data de emissão do RG.\n",
        "\n",
        "# Concatenando os vetores de CPF, RG e DT em strings.\n",
        "texto = ''.join(map(str, CPF))  # Converte a lista de inteiros CPF em uma string contínua.\n",
        "texto2 = ''.join(map(str, RG))  # Faz o mesmo para o vetor RG.\n",
        "texto_dt = ''.join(map(str, DT))  # Faz o mesmo para a data de emissão.\n",
        "\n",
        "# Carregando o modelo de perguntas e respostas da biblioteca Transformers.\n",
        "qa_pipeline = pipeline(\"question-answering\", model=\"distilbert-base-uncased-distilled-squad\")\n",
        "\n",
        "# Mensagem inicial para orientar o usuário.\n",
        "mensagem_inicial = \"Deseja validar RG e CPF? Se sim, digite 'RG' para RG e 'CPF' para CPF.\"\n",
        "\n",
        "# Função para calcular a validade do RG.\n",
        "def verificar_validade_rg(data_emissao):\n",
        "    # Converter a data de emissão para um objeto datetime.\n",
        "    data_emissao = datetime.strptime(data_emissao, \"%d%m%Y\")  # Formato esperado: DDMMYYYY.\n",
        "\n",
        "    # Obter a data atual.\n",
        "    data_atual = datetime.now()\n",
        "\n",
        "    # Calcular a diferença em anos entre a data atual e a data de emissão.\n",
        "    diferenca_anos = (data_atual - data_emissao).days / 365.25  # Converte dias em anos.\n",
        "\n",
        "    # Verificar validade: RG válido se tiver menos de 10 anos.\n",
        "    if diferenca_anos < 10:\n",
        "        return \"O RG está válido.\"\n",
        "    else:\n",
        "        return \"O RG está inválido (mais de 10 anos).\"\n",
        "\n",
        "# Função para validar RG ou CPF com base em uma pergunta do usuário.\n",
        "def answer_question(question):\n",
        "    global texto, texto2, texto_dt\n",
        "\n",
        "    if question.lower() in [\"sim\", \"s\"]:\n",
        "        return mensagem_inicial\n",
        "\n",
        "    elif question.lower() == \"cpf\":\n",
        "        numeros_encontrados = re.findall(r'\\d', texto)\n",
        "        if len(numeros_encontrados) == 11:\n",
        "            return f\"Ok, isto é um CPF válido: {texto}\"\n",
        "        else:\n",
        "            return \"O vetor não corresponde a um CPF válido.\"\n",
        "\n",
        "    elif question.lower() == \"rg\":\n",
        "        numeros_encontrados2 = re.findall(r'\\d', texto2)\n",
        "        if 7 <= len(numeros_encontrados2) <= 8:\n",
        "            validade_rg = verificar_validade_rg(texto_dt)\n",
        "            return f\"Ok, isto é um RG válido: {texto2}. {validade_rg}\"\n",
        "        else:\n",
        "            return \"O vetor não corresponde a um RG válido.\"\n",
        "\n",
        "    else:\n",
        "        return \"Você digitou errado.\"\n",
        "\n",
        "# Criando a interface do Gradio.\n",
        "with gr.Blocks() as app:\n",
        "    # Campo de entrada para o usuário digitar perguntas.\n",
        "    question_input = gr.Textbox(label=\"Digite sua pergunta\")\n",
        "\n",
        "    # Campo de saída para exibir respostas do chatbot.\n",
        "    answer_output = gr.Textbox(label=\"Resposta do chatbot\", interactive=False)\n",
        "\n",
        "    # Define a mensagem inicial como valor inicial da saída.\n",
        "    answer_output.value = mensagem_inicial\n",
        "\n",
        "    # Configura o campo de entrada para processar perguntas e exibir respostas.\n",
        "    question_input.submit(answer_question, inputs=question_input, outputs=answer_output)\n",
        "\n",
        "# Inicia a aplicação.\n",
        "app.launch()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 646
        },
        "id": "fozqfs1f6-ZG",
        "outputId": "61154a27-c9f0-49ab-d8e0-f4e33a984eab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running Gradio in a Colab notebook requires sharing enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://0c721dcd360ccbc9ca.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://0c721dcd360ccbc9ca.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## outros CHAT\n",
        "---------------\n"
      ],
      "metadata": {
        "id": "9DfExheC9Pc7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importa a biblioteca Gradio, que permite criar interfaces interativas de forma simples.\n",
        "import gradio as gr\n",
        "\n",
        "# Importa a função pipeline da biblioteca Transformers para carregar modelos pré-treinados.\n",
        "from transformers import pipeline\n",
        "\n",
        "# Define o texto de contexto que será usado para responder às perguntas.\n",
        "# Aqui, 'texto2' deve conter uma string que serve como base para o pipeline de perguntas e respostas.\n",
        "texto = texto2\n",
        "\n",
        "# Carrega um pipeline de perguntas e respostas usando um modelo pré-treinado.\n",
        "# \"distilbert-base-uncased-distilled-squad\" é um modelo leve e eficiente para tarefas de QA (Question Answering).\n",
        "qa_pipeline = pipeline(\"question-answering\", model=\"distilbert-base-uncased-distilled-squad\")\n",
        "\n",
        "# Define uma função que responde a perguntas com base no contexto fornecido.\n",
        "def answer_question(question):\n",
        "    if texto:  # Verifica se o texto de contexto foi fornecido.\n",
        "        # Usa o pipeline de perguntas e respostas para obter a resposta.\n",
        "        # A função recebe uma pergunta e o contexto (texto) para gerar uma resposta.\n",
        "        result = qa_pipeline(question=question, context=texto)\n",
        "        # Retorna a resposta gerada pelo modelo.\n",
        "        return result[\"answer\"]\n",
        "    else:\n",
        "        # Caso nenhum texto de contexto tenha sido definido, retorna uma mensagem informativa.\n",
        "        return \"Nenhum texto de contexto foi fornecido.\"\n",
        "\n",
        "# Cria a interface do usuário usando Gradio.\n",
        "with gr.Blocks() as app:\n",
        "    # Cria um campo de entrada de texto onde o usuário pode digitar uma pergunta.\n",
        "    question_input = gr.Textbox(label=\"Digite sua pergunta\")\n",
        "\n",
        "    # Cria um campo de saída para exibir a resposta do chatbot.\n",
        "    # O campo não é interativo, pois apenas exibe as respostas.\n",
        "    answer_output = gr.Textbox(label=\"Resposta do chatbot\", interactive=False)\n",
        "\n",
        "    # Configura o envio de perguntas e geração de respostas.\n",
        "    # Quando o usuário envia uma pergunta, a função 'answer_question' é chamada.\n",
        "    # A entrada do usuário ('question_input') é processada e a resposta é exibida no campo 'answer_output'.\n",
        "    question_input.submit(answer_question, inputs=question_input, outputs=answer_output)\n",
        "\n",
        "# Inicia a aplicação Gradio, abrindo uma interface no navegador.\n",
        "app.launch()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 383
        },
        "id": "Xcy45OMA9SIj",
        "outputId": "256ff58c-aa21-4249-c2b5-e41f951256db"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'gradio'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-60-4bc4114ec377>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Importa a biblioteca Gradio, que permite criar interfaces interativas de forma simples.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mgradio\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mgr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Importa a função pipeline da biblioteca Transformers para carregar modelos pré-treinados.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtransformers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpipeline\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'gradio'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    }
  ]
}